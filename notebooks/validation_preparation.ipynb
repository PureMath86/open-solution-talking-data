{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "DATA = '/mnt/ml-team/minerva/talking_data/data'\n",
    "FILES = '/mnt/ml-team/minerva/talking_data/files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(DATA, 'train.csv'),low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['click_time'] =  pd.to_datetime(train['click_time'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = pd.DatetimeIndex(train['click_time'])\n",
    "grouped_train = train.groupby([times.day, times.hour])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_day6_hour14.csv\n",
      "train_day6_hour15.csv\n",
      "train_day6_hour16.csv\n",
      "train_day6_hour17.csv\n",
      "train_day6_hour18.csv\n",
      "train_day6_hour19.csv\n",
      "train_day6_hour20.csv\n",
      "train_day6_hour21.csv\n",
      "train_day6_hour22.csv\n",
      "train_day6_hour23.csv\n",
      "train_day7_hour0.csv\n",
      "train_day7_hour1.csv\n",
      "train_day7_hour2.csv\n",
      "train_day7_hour3.csv\n",
      "train_day7_hour4.csv\n",
      "train_day7_hour5.csv\n",
      "train_day7_hour6.csv\n",
      "train_day7_hour7.csv\n",
      "train_day7_hour8.csv\n",
      "train_day7_hour9.csv\n",
      "train_day7_hour10.csv\n",
      "train_day7_hour11.csv\n",
      "train_day7_hour12.csv\n",
      "train_day7_hour13.csv\n",
      "train_day7_hour14.csv\n",
      "train_day7_hour15.csv\n",
      "train_day7_hour16.csv\n",
      "train_day7_hour17.csv\n",
      "train_day7_hour18.csv\n",
      "train_day7_hour19.csv\n",
      "train_day7_hour20.csv\n",
      "train_day7_hour21.csv\n",
      "train_day7_hour22.csv\n",
      "train_day7_hour23.csv\n",
      "train_day8_hour0.csv\n",
      "train_day8_hour1.csv\n",
      "train_day8_hour2.csv\n",
      "train_day8_hour3.csv\n",
      "train_day8_hour4.csv\n",
      "train_day8_hour5.csv\n",
      "train_day8_hour6.csv\n",
      "train_day8_hour7.csv\n",
      "train_day8_hour8.csv\n",
      "train_day8_hour9.csv\n",
      "train_day8_hour10.csv\n",
      "train_day8_hour11.csv\n",
      "train_day8_hour12.csv\n",
      "train_day8_hour13.csv\n",
      "train_day8_hour14.csv\n",
      "train_day8_hour15.csv\n",
      "train_day8_hour16.csv\n",
      "train_day8_hour17.csv\n",
      "train_day8_hour18.csv\n",
      "train_day8_hour19.csv\n",
      "train_day8_hour20.csv\n",
      "train_day8_hour21.csv\n",
      "train_day8_hour22.csv\n",
      "train_day8_hour23.csv\n",
      "train_day9_hour0.csv\n",
      "train_day9_hour1.csv\n",
      "train_day9_hour2.csv\n",
      "train_day9_hour3.csv\n",
      "train_day9_hour4.csv\n",
      "train_day9_hour5.csv\n",
      "train_day9_hour6.csv\n",
      "train_day9_hour7.csv\n",
      "train_day9_hour8.csv\n",
      "train_day9_hour9.csv\n",
      "train_day9_hour10.csv\n",
      "train_day9_hour11.csv\n",
      "train_day9_hour12.csv\n",
      "train_day9_hour13.csv\n",
      "train_day9_hour14.csv\n",
      "train_day9_hour15.csv\n",
      "train_day9_hour16.csv\n"
     ]
    }
   ],
   "source": [
    "for (day, hour), train_chunk in grouped_train:\n",
    "    chunk_filename = 'train_day{}_hour{}.csv'.format(day, hour)\n",
    "    print(chunk_filename)\n",
    "    chunk_filepath = os.path.join(FILES, chunk_filename)\n",
    "    train_chunk.to_csv(chunk_filepath, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from itertools import product\n",
    "\n",
    "def read_csv_chunks(chunks_dir, days=[], hours=[]):\n",
    "    filepaths = []\n",
    "    for day, hour in product(days, hours):\n",
    "        filepaths.extend(glob.glob('{}/train_day{}_hour{}.csv'.format(chunks_dir, day, hour)))            \n",
    "    data_chunks = []\n",
    "    for filepath in filepaths:\n",
    "        data_chunk = pd.read_csv(filepath)\n",
    "        data_chunks.append(data_chunk)\n",
    "    data_chunks = pd.concat(data_chunks, axis=0)\n",
    "    return data_chunks\n",
    "        \n",
    "df = read_csv_chunks(FILES, days=[8], hours=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3065649, 8)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpu_py3",
   "language": "python",
   "name": "cpu_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
